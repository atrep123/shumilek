{
  "files": [
    {
      "path": "mini_ai/markov.py",
      "content": "from __future__ import annotations\nimport json\nimport random\n\nclass MarkovChain:\n    def __init__(self, order: int = 1):\n        if order <= 0:\n            raise ValueError(\"Order must be greater than 0.\")\n        self.order = order\n        self.transitions = {}\n\n    def train(self, text: str) -> None:\n        for i in range(len(text) - self.order):\n            context = text[i:i + self.order]\n            next_char = text[i + self.order]\n            if context not in self.transitions:\n                self.transitions[context] = {}\n            if next_char not in self.transitions[context]:\n                self.transitions[context][next_char] = 0\n            self.transitions[context][next_char] += 1\n        # Handle the last part of the text\n        context = text[-self.order:]\n        if context not in self.transitions:\n            self.transitions[context] = {}\n        if '' not in self.transitions[context]:\n            self.transitions[context][''] = 0\n        self.transitions[context][''] += 1\n\n    def generate(self, length: int, seed: str | None = None, random_seed: int | None = None) -> str:\n        if random_seed is not None:\n            random.seed(random_seed)\n        if seed is None or len(seed) < self.order:\n            context = random.choice(list(self.transitions.keys()))\n        else:\n            context = seed[:self.order]\n        result = list(context)\n        for _ in range(length - self.order):\n            next_char = random.choices(list(self.transitions[context].keys()), weights=self.transitions[context].values())[0]\n            if next_char == '':\n                break\n            result.append(next_char)\n            context = ''.join(result[-self.order:])\n        return ''.join(result)\n\n    def to_dict(self) -> dict:\n        return {\n            \"order\": self.order,\n            \"transitions\": self.transitions\n        }\n\n    @classmethod\n    def from_dict(cls, data: dict) -> MarkovChain:\n        mc = cls(data[\"order\"])\n        mc.transitions = data[\"transitions\"]\n        return mc\n"
    },
    {
      "path": "mini_ai/cli.py",
      "content": "import argparse\nimport json\nfrom .markov import MarkovChain\n\ndef main(args=None):\n    parser = argparse.ArgumentParser(description='Markov Chain Text Generator')\n    subparsers = parser.add_subparsers(dest='command', required=True)\n\n    train_parser = subparsers.add_parser('train', help='Train a Markov Chain model')\n    train_parser.add_argument('--input', type=str, required=True, help='Input text file')\n    train_parser.add_argument('--model-out', type=str, required=True, help='Output model file')\n    train_parser.add_argument('--order', type=int, default=1, help='Order of the Markov Chain')\n\n    generate_parser = subparsers.add_parser('generate', help='Generate text using a trained Markov Chain model')\n    generate_parser.add_argument('--model', type=str, required=True, help='Input model file')\n    generate_parser.add_argument('--length', type=int, default=100, help='Length of the generated text')\n    generate_parser.add_argument('--seed', type=str, help='Seed for the generated text')\n    generate_parser.add_argument('--random-seed', type=int, help='Random seed for reproducibility')\n\n    args = parser.parse_args(args)\n\n    if args.command == 'train':\n        with open(args.input, 'r', encoding='utf-8') as f:\n            text = f.read()\n        mc = MarkovChain(order=args.order)\n        mc.train(text)\n        with open(args.model_out, 'w', encoding='utf-8') as f:\n            json.dump(mc.to_dict(), f)\n    elif args.command == 'generate':\n        with open(args.model, 'r', encoding='utf-8') as f:\n            data = json.load(f)\n        mc = MarkovChain.from_dict(data)\n        generated_text = mc.generate(length=args.length, seed=args.seed, random_seed=args.random_seed)\n        print(generated_text)\n\nif __name__ == '__main__':\n    main()\n"
    }
  ],
  "notes": "Fixed syntax and indentation errors in the provided files."
}