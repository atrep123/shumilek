```python
# path: src/dataset.py

import numpy as np

class DatasetGenerator:
    @staticmethod
    def generate_linearly_separable_data(n_samples=100, n_features=2):
        X = np.random.randn(n_samples, n_features)
        y = (X[:, 0] + X[:, 1] > 0).astype(int)
        return X, y

class TrainTestSplit:
    @staticmethod
    def split(X, y, test_size=0.25, random_state=None):
        if random_state is not None:
            np.random.seed(random_state)
        indices = np.arange(len(X))
        np.random.shuffle(indices)
        n_test = int(test_size * len(X))
        X_train, X_test = X[indices[n_test:]], X[indices[:n_test]]
        y_train, y_test = y[indices[n_test:]], y[indices[:n_test]]
        return (X_train, y_train), (X_test, y_test)

class StandardScaler:
    def fit(self, X):
        self.mean_ = np.mean(X, axis=0)
        self.std_ = np.std(X, axis=0)
    
    def transform(self, X):
        return (X - self.mean_) / self.std_
    
    def fit_transform(self, X):
        self.fit(X)
        return self.transform(X)
```

```python
# path: src/logistic.py

import numpy as np

class LogisticRegression:
    def __init__(self, learning_rate=0.1, n_iters=5000):
        self.learning_rate = learning_rate
        self.n_iters = n_iters
    
    @staticmethod
    def sigmoid(z):
        return 1 / (1 + np.exp(-z))
    
    def fit(self, X, y):
        n_samples, n_features = X.shape
        self.weights = np.zeros(n_features)
        self.bias = 0
        
        for _ in range(self.n_iters):
            linear_model = np.dot(X, self.weights) + self.bias
            predictions = LogisticRegression.sigmoid(linear_model)
            
            dw = (1 / n_samples) * np.dot(X.T, (predictions - y))
            db = (1 / n_samples) * np.sum(predictions - y)
            
            self.weights -= self.learning_rate * dw
            self.bias -= self.learning_rate * db
    
    def predict(self, X):
        linear_model = np.dot(X, self.weights) + self.bias
        predictions = LogisticRegression.sigmoid(linear_model)
        return [1 if i > 0.5 else 0 for i in predictions]
    
    def predict_proba(self, X):
        linear_model = np.dot(X, self.weights) + self.bias
        return LogisticRegression.sigmoid(linear_model)
```

```python
# path: src/metrics.py

import numpy as np

def accuracy(y_true, y_pred):
    return np.sum(y_true == y_pred) / len(y_true)

def confusion_matrix(y_true, y_pred):
    tp = np.sum((y_true == 1) & (y_pred == 1))
    fp = np.sum((y_true == 0) & (y_pred == 1))
    fn = np.sum((y_true == 1) & (y_pred == 0))
    tn = np.sum((y_true == 0) & (y_pred == 0))
    return tp, fp, fn, tn

def precision_recall_f1(tp, fp, fn):
    precision = tp / (tp + fp)
    recall = tp / (tp + fn)
    f1_score = 2 * (precision * recall) / (precision + recall)
    return precision, recall, f1_score
```

```python
# path: src/pipeline.py

import numpy as np
from
