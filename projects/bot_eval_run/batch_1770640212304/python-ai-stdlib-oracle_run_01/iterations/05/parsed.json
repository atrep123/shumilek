{
  "mode": "full",
  "files": [
    {
      "path": "README.md",
      "content": "# Mini AI\n\nThis is a simple character-level Markov chain generator implemented in Python without using any external libraries.\n\n## Features\n\n- Implements a MarkovChain class with methods for training and generating text based on the trained model.\n- Provides a CLI interface to train the model from a text file and generate new text using the trained model.\n\n## Installation\n\nTo use this package, you can clone the repository and install it via pip:\n\n```bash\ngit clone https://github.com/yourusername/mini_ai.git\ncd mini_ai/\npip install .\n```\n\n## Usage\n\n### Training the Model\n\nTo train the model, use the following command:\n\n```bash\npython -m mini_ai.cli train --input <path-to-text-file> --model-out <path-to-output-model> --order <int>\n```\n\n### Generating Text\n\nTo generate text using the trained model, use the following command:\n\n```bash\npython -m mini_ai.cli generate --model <path-to-model> --length <int> [--seed <str>] [--random-seed <int>]\n```\n\n## Documentation\n\nFor more detailed documentation, please refer to the source code or generated docs.\n"
    },
    {
      "path": "mini_ai/__init__.py",
      "content": "from .markov import MarkovChain\nfrom .cli import main\n"
    },
    {
      "path": "mini_ai/markov.py",
      "content": "from typing import Optional, List, Dict, Any\nimport random\n\nclass MarkovChain:\n    def __init__(self, order: int = 1):\n        self.order = order\n        self.transitions: Dict[str, Dict[str, int]] = {}\n\n    def train(self, text: str) -> None:\n        for i in range(len(text) - self.order):\n            context = text[i:i + self.order]\n            next_char = text[i + self.order]\n            if context not in self.transitions:\n                self.transitions[context] = {next_char: 1}\n            else:\n                if next_char not in self.transitions[context]:\n                    self.transitions[context][next_char] = 1\n                else:\n                    self.transitions[context][next_char] += 1\n\n    def generate(self, length: int, seed: str | None = None, random_seed: int | None = None) -> str:\n        if random_seed is not None:\n            random.seed(random_seed)\n        elif seed is not None:\n            random.seed(seed)\n\n        if seed is None or seed not in self.transitions:\n            context = random.choice(list(self.transitions.keys()))\n        else:\n            context = seed\n\n        result = seed if seed is not None else \"\"\n        for _ in range(length):\n            if context in self.transitions and len(self.transitions[context]) > 0:\n                next_char = random.choice(list(self.transitions[context].keys()))\n                result += next_char\n                context = result[-self.order:]\n            else:\n                break\n        return result\n\n    def to_dict(self) -> dict:\n        return {\"order\": self.order, \"transitions\": self.transitions}\n\n    @staticmethod\n    def from_dict(data: Dict[str, Any]) -> 'MarkovChain':\n        mc = MarkovChain(order=data[\"order\"])\n        mc.transitions = data[\"transitions\"]\n        return mc\n"
    },
    {
      "path": "mini_ai/cli.py",
      "content": "import argparse\nimport json\nfrom .markov import MarkovChain\n\ndef main(argv: Optional[List[str]] = None) -> int:\n    parser = argparse.ArgumentParser()\n    subparsers = parser.add_subparsers()\n\n    train_parser = subparsers.add_parser(\"train\")\n    train_parser.add_argument(\"--input\", type=str, required=True)\n    train_parser.add_argument(\"--model-out\", type=str, required=True)\n    train_parser.add_argument(\"--order\", type=int, required=True)\n    train_parser.set_defaults(func=train)\n\n    generate_parser = subparsers.add_parser(\"generate\")\n    generate_parser.add_argument(\"--model\", type=str, required=True)\n    generate_parser.add_argument(\"--length\", type=int, required=True)\n    generate_parser.add_argument(\"--seed\")\n    generate_parser.add_argument(\"--random-seed\", type=int)\n    generate_parser.set_defaults(func=generate)\n\n    args = parser.parse_args(argv)\n    return args.func(args) if hasattr(args, \"func\") else 0\n\ndef train(args):\n    with open(args.input, \"r\", encoding=\"utf-8\") as f:\n        text = f.read()\n    mc = MarkovChain(order=args.order)\n    mc.train(text)\n    with open(args.model_out, \"w\", encoding=\"utf-8\") as f:\n        json.dump(mc.to_dict(), f)\n    return 0\n\ndef generate(args):\n    with open(args.model, \"r\", encoding=\"utf-8\") as f:\n        model = MarkovChain.from_dict(json.load(f))\n    generated_text = model.generate(length=args.length, seed=args.seed, random_seed=args.random_seed)\n    print(generated_text)\n    return 0\n"
    }
  ],
  "notes": "optional"
}