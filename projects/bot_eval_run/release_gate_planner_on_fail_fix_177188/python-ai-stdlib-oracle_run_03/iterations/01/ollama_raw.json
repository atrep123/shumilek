{
  "model": "qwen2.5-coder:14b",
  "created_at": "2026-02-23T10:07:48.902321Z",
  "message": {
    "role": "assistant",
    "content": "{\n  \"files\": [\n    {\n      \"path\": \"README.md\",\n      \"content\": \"# mini_ai\\n\\nThis is a simple implementation of a character-level Markov chain generator using the n-gram model. The package includes a `MarkovChain` class for training and generating text, as well as a command-line interface for interacting with the model.\\n\\n## Installation\\n\\nTo use this package, simply clone the repository and run the following commands:\\n\\n```bash\\npython -m mini_ai.cli train --input <path> --model-out <path> --order <int>\\npython -m mini_ai.cli generate --model <path> --length <int> [--seed <str>] [--random-seed <int>]\\n```\\n\\n## Usage\\n\\n### Training a Model\\n\\nTo train a model, use the `train` subcommand:\\n\\n```bash\\npython -m mini_ai.cli train --input <path> --model-out <path> --order <int>\\n```\\n\\nThis will read the input text from `<path>` and save the trained model to `<path>`.\\n\\n### Generating Text\\n\\nTo generate text using a trained model, use the `generate` subcommand:\\n\\n```bash\\npython -m mini_ai.cli generate --model <path> --length <int> [--seed <str>] [--random-seed <int>]\\n```\\n\\nThis will read the trained model from `<path>` and generate text of length `<int>`, optionally starting with a given `seed` and using a specific `random_seed` for reproducibility.\\n\"\n    },\n    {\n      \"path\": \"mini_ai/__init__.py\",\n      \"content\": \"\"\n    },\n    {\n      \"path\": \"mini_ai/markov.py\",\n      \"content\": \"from __future__ import annotations\\nimport random\\nclass MarkovChain:\\n    def __init__(self, order: int = 1):\\n        if order <= 0:\\n            raise ValueError(\\\"Order must be greater than 0\\\")\\n        self.order = order\\n        self.transitions = {}\\n\\n    def train(self, text: str) -> None:\\n        for i in range(len(text) - self.order):\\n            context = text[i:i + self.order]\\n            next_char = text[i + self.order]\\n            if context not in self.transitions:\\n                self.transitions[context] = {}\\n            if next_char not in self.transitions[context]:\\n                self.transitions[context][next_char] = 0\\n            self.transitions[context][next_char] += 1\\n\\n    def generate(self, length: int, seed: str | None = None, random_seed: int | None = None) -> str:\\n        if random_seed is not None:\\n            random.seed(random_seed)\\n        if seed is None or len(seed) < self.order:\\n            context = random.choice(list(self.transitions.keys()))\\n        else:\\n            context = seed[:self.order]\\n        result = list(context)\\n        for _ in range(length - self.order):\\n            next_char = random.choices(\\n                population=list(self.transitions[context].keys()),\\n                weights=self.transitions[context].values(),\\n                k=1\\n            )[0]\\n            result.append(next_char)\\n            context = ''.join(result[-self.order:])\\n        return ''.join(result)\\n\\n    def to_dict(self) -> dict:\\n        return {\\n            \\\"order\\\": self.order,\\n            \\\"transitions\\\": self.transitions\\n        }\\n\\n    @classmethod\\ndef from_dict(cls, d: dict) -> \\\"MarkovChain\\\":\\n        mc = cls(order=d[\\\"order\\\"])\\n        mc.transitions = d[\\\"transitions\\\"]\\n        return mc\"\n    },\n    {\n      \"path\": \"mini_ai/cli.py\",\n      \"content\": \"import argparse\\nimport json\\nfrom mini_ai.markov import MarkovChain\\ndef main(argv: list[str] | None = None) -> int:\\n    parser = argparse.ArgumentParser(description=\\\"Markov Chain Text Generator\\\")\\n    subparsers = parser.add_subparsers(dest='command')\\n\\n    train_parser = subparsers.add_parser('train', help='Train a Markov chain model')\\n    train_parser.add_argument('--input', required=True, type=str, help='Input text file path')\\n    train_parser.add_argument('--model-out', required=True, type=str, help='Output model file path')\\n    train_parser.add_argument('--order', required=True, type=int, help='Order of the Markov chain')\\n\\n    generate_parser = subparsers.add_parser('generate', help='Generate text using a trained Markov chain model')\\n    generate_parser.add_argument('--model', required=True, type=str, help='Trained model file path')\\n    generate_parser.add_argument('--length', required=True, type=int, help='Length of the generated text')\\n    generate_parser.add_argument('--seed', type=str, help='Seed for the generated text')\\n    generate_parser.add_argument('--random-seed', type=int, help='Random seed for reproducibility')\\n\\n    args = parser.parse_args(argv)\\n\\n    if args.command == 'train':\\n        with open(args.input, 'r', encoding='utf-8') as f:\\n            text = f.read()\\n        mc = MarkovChain(order=args.order)\\n        mc.train(text)\\n        with open(args.model_out, 'w', encoding='utf-8') as f:\\n            json.dump(mc.to_dict(), f)\\n        return 0\\n    elif args.command == 'generate':\\n        with open(args.model, 'r', encoding='utf-8') as f:\\n            d = json.load(f)\\n        mc = MarkovChain.from_dict(d)\\n        generated_text = mc.generate(length=args.length, seed=args.seed, random_seed=args.random_seed)\\n        print(generated_text)\\n        return 0\\n    else:\\n        parser.print_help()\\n        return 1\"\n    }\n  ],\n  \"notes\": \"\"\n}"
  },
  "done": true,
  "done_reason": "stop",
  "total_duration": 40718055500,
  "load_duration": 61670800,
  "prompt_eval_count": 1418,
  "prompt_eval_duration": 14745700,
  "eval_count": 1308,
  "eval_duration": 15705493000
}