{
  "mode": "full",
  "files": [
    {
      "path": "README.md",
      "content": "mini-ai\n"
    },
    {
      "path": "mini_ai/__init__.py",
      "content": "from .markov import MarkovChain\nfrom .cli import main\n\n__all__ = [\"MarkovChain\", \"main\"]\n"
    },
    {
      "path": "mini_ai/markov.py",
      "content": "from __future__ import annotations\nfrom typing import Dict, List, Tuple, Optional, TypeVar, Generic, Set, Any, cast\nfrom collections import defaultdict\n\n\nT = TypeVar('T')\n\n\nclass MarkovChain(Generic[T]):\n    \"\"\"A character-level Markov chain generator.\"\n\n    order: int\n    transitions: Dict[str, Dict[Tuple[T, ...], Dict[T, int]]]\n\n    def __init__(self, order: int = 1):\n        if order < 1:\n            raise ValueError(\"Order must be at least 1.\")\n        self.order = order\n        self.transitions = defaultdict(lambda: defaultdict(lambda: defaultdict(int)))\n\n    def train(self, text: str) -> None:\n        \"\"\"\n        Train the Markov chain on the given text.\n        \n        Args:\n            text: Input text for training.\n        \"\"\"\n        # Normalize the text to lowercase to make it case-insensitive\n        text = text.lower()\n        # Add start and end markers\n        text = \"\\n\" + text + \"\\n\"\n        # Iterate over the text with a sliding window of size `order`\n        for i in range(len(text) - self.order + 1):\n            context = text[i:i+self.order]\n            next_char = text[i+self.order]\n            self.transitions[context][next_char] += 1\n\n    def generate(self, length: int, seed: str | None = None, random_seed: int | None = None) -> str:\n        \"\"\"\n        Generate a text of given length using the trained Markov chain.\n        \n        Args:\n            length: Length of the generated text.\n            seed: Seed string to start generation. If None, start with a random context.\n            random_seed: Seed for the random number generator.\n        \n        Returns:\n            Generated text.\n        \"\"\"\n        # If no seed is provided, choose a random starting context from the keys\n        if seed is None:\n            # Choose a random starting context from the keys\n            import random\n            if random_seed is not None:\n                random.seed(random_seed)\n            contexts = list(self.transitions.keys())\n            if not contexts:\n                raise ValueError(\"No training data available.\")\n            seed = random.choice(contexts)\n            # Ensure the seed is a string of length `order`\n            if len(seed) != self.order:\n                seed = seed[:self.order]\n\n        # Start with the seed\n        generated = seed\n        # The current context is the seed\n        current_context = seed\n        # If we have a random seed, set it\n        if random_seed is not None:\n            import random\n            random.seed(random_seed)\n\n        # Generate the rest of the text\n        for _ in range(length - self.order):\n            # Get the next character distribution from the current context\n            if current_context in self.transitions:\n                next_dist = self.transitions[current_context]\n                # If there are no transitions, break\n                if not next_dist:\n                    break\n                # Choose a next character according to the weights\n                choices = list(next_dist.keys())\n                weights = [next_dist[c] for c in choices]\n                next_char = random.choices(choices, weights=weights, k=1)[0]\n                generated += next_char\n                # Update the current context by shifting one character\n                current_context = current_context[1:] + next_char\n            else:\n                # If the current context is not in the transitions, break\n                break\n\n        return generated\n\n    def to_dict(self) -> dict:\n        \"\"\"\n        Convert the Markov chain to a dictionary for serialization.\n        \n        Returns:\n            Dictionary representation of the Markov chain.\n        \"\"\"\n        transitions_dict = {}\n        for context, inner_dict in self.transitions.items():\n            # For each context, create a dictionary of next_char: count\n            next_dict = {}\n            for next_char, count in inner_dict.items():\n                next_dict[next_char] = count\n            transitions_dict[context] = next_dict\n        return {\"order\": self.order, \"transitions\": transitions_dict}\n\n    @classmethod\n    def from_dict(cls, d: dict) -> \"MarkovChain\":\n        \"\"\"\n        Create a MarkovChain instance from a dictionary.\n        \n        Args:\n            d: Dictionary containing the order and transitions.\n        \n        Returns:\n            MarkovChain instance.\n        \"\"\"\n        mc = cls(d[\"order\"])\n        transitions = d[\"transitions\"]\n        for context, next_dict in transitions.items():\n            for next_char, count in next_dict.items():\n                mc.transitions[context][next_char] = count\n        return mc\n\n\n"
    },
    {
      "path": "mini_ai/cli.py",
      "content": "import argparse\nimport json\nimport sys\n\nfrom mini_ai.markov import MarkovChain\n\n\ndef main(argv=None):\n    \"\"\"\n    Main function for command line interface.\n    \n    Args:\n        argv: List of command line arguments, or None to use sys.argv.\n    \n    Returns:\n        Exit code.\n    \"\"\"\n    if argv is None:\n        argv = sys.argv\n    parser = argparse.ArgumentParser(description=\"Markov Chain Text Generator.\")\n    subparsers = parser.add_subparsers(dest=\"command\", required=True)\n\n    # Train subcommand\n    train_parser = subparsers.add_parser(\"train\", help=\"Train a Markov chain model.\")\n    train_parser.add_argument(\"--input\", type=str, required=True, help=\"Input text file path.\")\n    train_parser.add_argument(\"--model-out\", type=str, required=True, help=\"Output model file path.\")\n    train_parser.add_argument(\"--order\", type=int, default=1, help=\"Order of the Markov chain.\")\n    train_parser.set_defaults(command=\"train\")\n\n    # Generate subcommand\n    generate_parser = subparsers.add_parser(\"generate\", help=\"Generate text using a Markov chain model.\")\n    generate_parser.add_argument(\"--model\", type=str, required=True, help=\"Input model file path.\")\n    generate_parser.add_argument(\"--length\", type=int, default=10, help=\"Length of the generated text.\")\n    generate_parser.add_argument(\"--seed\", type=str, default=None, help=\"Seed string to start generation.\")\n    generate_parser.add_argument(\"--random-seed\", type=int, default=None, help=\"Seed for the random number generator.\")\n    generate_parser.set_defaults(command=\"generate\")\n\n    args = parser.parse_args(argv[1:])\n\n    if args.command == \"train\":\n        # Train the model\n        mc = MarkovChain(order=args.order)\n        with open(args.input, \"r\", encoding=\"utf-8\") as f:\n            text = f.read()\n        mc.train(text)\n        d = mc.to_dict()\n        with open(args.model_out, \"w\", encoding=\"utf-8\") as f:\n            json.dump(d, f, ensure_ascii=False, indent=4)\n        return 0\n\n    elif args.command == \"generate\":\n        # Load the model\n        with open(args.model, \"r\", encoding=\"utf-8\") as f:\n            d = json.load(f)\n        mc = MarkovChain.from_dict(d)\n        generated = mc.generate(length=args.length, seed=args.seed, random_seed=args.random_seed)\n        print(generated)\n        return 0\n\n    else:\n        parser.print_help()\n        return 2\n\nif __name__ == \"__main__\":\n    sys.exit(main())\n"
    }
  ],
  "notes": "The implementation includes the following:\n- The MarkovChain class with order and transitions (a nested defaultdict structure).\n- The train method processes the text and builds the transition counts.\n- The generate method uses the seed and random seed to produce deterministic or random text.\n- The to_dict and from_dict methods for serialization.\n- The CLI handles both train and generate commands with argparse.\n\nNote: The code uses future annotations for type hints to ensure compatibility with Python 3.12.\n"
}